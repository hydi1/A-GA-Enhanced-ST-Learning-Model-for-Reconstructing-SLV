import random
import numpy as np
import os
import torch
from exp.exp_long_term_forecasting import Exp_Long_Term_Forecast
from torchinfo import summary
def count_param(model):
    param_count = 0
    for param in model.parameters():
        param_count += param.view(-1).size()[0]
    return param_count

def set_seed(seed):
    """
    è®¾ç½®éšæœºç§å­ä»¥ç¡®ä¿å¯é‡å¤æ€§
    """
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    if torch.cuda.is_available():
        torch.cuda.manual_seed(seed)
        torch.cuda.manual_seed_all(seed)
        torch.backends.cudnn.deterministic = True
        torch.backends.cudnn.benchmark = False
BASE_DIR = os.path.dirname(os.path.abspath(__file__))
CHECKPOINT_DIR = os.path.join(BASE_DIR, "checkpoints")

def train_and_evaluate_model(seed=42):
    """
    ä½¿ç”¨æä¾›çš„è®­ç»ƒã€éªŒè¯å’Œæµ‹è¯•æ•°æ®è®­ç»ƒå¹¶è¯„ä¼° SOFTS æ¨¡å‹
    """
    # è®¾ç½®éšæœºç§å­
    set_seed(seed)

    # é…ç½®å®éªŒå‚æ•°
    args = {
        'task_name': 'uvst',
        'model_id': f"seed{seed}",
        'model': 'GAConvGRU',
        'data': 'ssta',
        'features': 'MS',
        'learning_rate': 0.0005,
        'seq_len': 12,
        'label_len': 12,
        'pred_len': 12,
        'd_model': 64,
        'e_layers': 2,
        'd_layers': 1,
        'd_ff': 256,
        'factor': 1,
        'embed': 'timeF',
        'distil': True,
        'dropout': 0.0,
        'activation': 'gelu',
        'use_gpu': True,
        'train_epochs': 128,
        'batch_size': 16,
        'patience': 128,
        'use_norm': False,
        'd_core': 512,
        'freq': 'D',
        'input_size': 1056,
        'hidden_size': 1056,
        'output_size': 1,
        'num_layers': 3,
        'root_path': r'D:\CGI2025ä»£ç \Northeast Pacific SANTA MONICA\Data',
        'data_path': 'TSuv_data_368.npy',
        'target_path': r"D:\CGI2025ä»£ç \Northeast Pacific SANTA MONICA\Data\Yénan -1993_2023.xlsx",
        'target': 'OT',
        'seasonal_patterns': 'Monthly',
        'num_workers': 4,
        'use_amp': False,
        'output_attention': False,
        'lradj': 'type1',
        'checkpoints': CHECKPOINT_DIR,
        'save_model': True,
        'device_ids': [0],
        'scale': True,
        'num_heads': 4,
    }

    # åˆå§‹åŒ–å®éªŒ
    exp = Exp_Long_Term_Forecast(args)
    # å¼€å§‹è®­ç»ƒ
    print(f"å¼€å§‹è®­ç»ƒï¼Œæ¨¡å‹ ID: {args['model_id']}, ç§å­: {seed}")
    model = exp._build_model()
    # è®¡ç®—å¹¶æ‰“å°å‚æ•°é‡
    print("æ€»å¯è®­ç»ƒå‚æ•°é‡ï¼š", count_param(model))
    # è·å–ä¸€ä¸ªçœŸå®çš„è¾“å…¥æ‰¹æ¬¡
    train_data, train_loader = exp._get_data(flag='train')
    batch = next(iter(train_loader))
    batch_x, batch_y, batch_x_mark, batch_y_mark = batch

    # ç§»åŠ¨åˆ°ä¸æ¨¡å‹ç›¸åŒçš„è®¾å¤‡
    device = torch.device('cuda' if args['use_gpu'] and torch.cuda.is_available() else 'cpu')
    batch_x = batch_x.float().to(device)
    batch_x_mark = batch_x_mark.float().to(device) if batch_x_mark is not None else None
    batch_y = batch_y.float().to(device)
    batch_y_mark = batch_y_mark.float().to(device) if batch_y_mark is not None else None

    # æ„é€  x_decï¼ˆæ ¹æ®ä½ çš„ forward æ–¹æ³•é€»è¾‘ï¼‰
    dec_inp = batch_y

    # ä½¿ç”¨ input_data ä¼ é€’å®é™…è¾“å…¥
    input_data = (batch_x, batch_x_mark, dec_inp, batch_y_mark)
    print(summary(model, input_data=input_data))
    exp.train(args)
    print("è®­ç»ƒå®Œæˆï¼")
    # æ˜¾å¼æ„å»ºæ¨¡å‹ä»¥è®¿é—®å®ƒ

    # åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°
    print("å¼€å§‹åœ¨éªŒè¯é›†ä¸Šè¯„ä¼°...")
    setting = '{}_{}_{}_{}_ft{}_sl{}_ll{}_pl{}_dm{}_el{}_dl{}_df{}_fc{}_eb{}_dt{}_{}'.format(
        args['task_name'],
        args['model_id'],
        args['model'],
        args['data'],
        args['features'],
        args['seq_len'],
        args['label_len'],
        args['pred_len'],
        args['d_model'],
        args['e_layers'],
        args['d_layers'],
        args['d_ff'],
        args['factor'],
        args['embed'],
        args['distil'],
        args['target']
    )
    result = exp.test(setting)

    # æå–æŒ‡æ ‡ï¼ˆæ ¹æ®ç®€åŒ–åçš„ test å‡½æ•°ï¼‰
    rmse_norm = result.get('rmse_norm')
    mae_norm = result.get('mae_norm')
    r2_eff_norm = result.get('r2_eff_norm')
    rmse_unnorm = result.get('rmse_unnorm')
    mae_unnorm = result.get('mae_unnorm')

    print(f"ç§å­ {seed} è¯„ä¼°å®Œæˆï¼")
    print(f"  å½’ä¸€åŒ–+å»é‡å : RMSE={rmse_norm:.4f}, MAE={mae_norm:.4f}, R2_eff={r2_eff_norm:.4f}")
    print(f"  åå½’ä¸€åŒ–+å»é‡å : RMSE={rmse_unnorm:.4f}, MAE={mae_unnorm:.4f}")

    return rmse_norm, mae_norm, r2_eff_norm, rmse_unnorm, mae_unnorm

if __name__ == "__main__":

    seed_list = [
        42, 43, 44, 45, 46,
        100, 200, 300, 400, 500,
        123, 234, 345, 456, 567,
        678, 789, 888, 999, 1000,

        1666, 1777, 1888, 1999, 2024,
        2025, 2048, 2077, 2099, 2121,
        2222, 2333, 2444, 2555, 2666,
        2777, 2888, 2999, 3001, 3333,
        3456, 3579, 3690, 4040, 5050
    ]

    results = []
    for seed in seed_list:
        # æ¥æ”¶ test è¿”å›çš„äº”ä¸ªæŒ‡æ ‡
        rmse_norm, mae_norm, r2_eff_norm, rmse_unnorm, mae_unnorm = train_and_evaluate_model(seed=seed)
        results.append((seed, rmse_norm, mae_norm, r2_eff_norm, rmse_unnorm, mae_unnorm))

    # æŒ‰ RMSE(norm) å‡åºæ’åºï¼Œæ‰¾åˆ°æœ€å¥½çš„ç§å­ï¼ˆRMSE è¶Šå°è¶Šå¥½ï¼‰
    results.sort(key=lambda x: x[1])
    best_seed, b_rmse_norm, b_mae_norm, b_r2_eff, b_rmse_unnorm, b_mae_unnorm = results[0]

    print("\n" + "=" * 100)
    print(f"{'æ‰€æœ‰ç§å­æµ‹è¯•ç»“æœ (æŒ‰ RMSE(norm) æ’åº)':^100}")
    print("-" * 100)
    print(f"{'ç§å­':<8} | {'RMSE(norm)':<12} | {'MAE(norm)':<12} | {'R2_eff(norm)':<14} | {'RMSE(unnorm)':<14} | {'MAE(unnorm)':<12}")
    print("-" * 100)
    for seed, rn, mn, r2eff, ru, mu in results:
        print(f"{seed:<8} | {rn:<12.4f} | {mn:<12.4f} | {r2eff:<14.4f} | {ru:<14.4f} | {mu:<12.4f}")
    print("-" * 100)

    print(f"\nğŸ¥‡ æœ€ä½³ç§å­: {best_seed}")
    print(f"  > å½’ä¸€åŒ–+å»é‡å : RMSE={b_rmse_norm:.4f}, MAE={b_mae_norm:.4f}, R2_eff={b_r2_eff:.4f}")
    print(f"  > åå½’ä¸€åŒ–+å»é‡å : RMSE={b_rmse_unnorm:.4f}, MAE={b_mae_unnorm:.4f}")

    # è®¡ç®—æ‰€æœ‰æ€§èƒ½æŒ‡æ ‡çš„å¹³å‡æ€§èƒ½
    rmse_norms = [r[1] for r in results]
    mae_norms = [r[2] for r in results]
    r2_effs = [r[3] for r in results]
    rmse_unnorms = [r[4] for r in results]
    mae_unnorms = [r[5] for r in results]

    print("\n" + "=" * 60)
    print(f"{'å¹³å‡æ€§èƒ½ç»Ÿè®¡ (æ‰€æœ‰ç§å­)':^60}")
    print("-" * 60)
    print(f"å½’ä¸€åŒ–+å»é‡å  RMSE: {np.mean(rmse_norms):.4f} Â± {np.std(rmse_norms, ddof=1):.4f}")
    print(f"å½’ä¸€åŒ–+å»é‡å  MAE:  {np.mean(mae_norms):.4f} Â± {np.std(mae_norms, ddof=1):.4f}")
    print(f"R2_eff(å½’ä¸€åŒ–+å»é‡å ): {np.mean(r2_effs):.4f} Â± {np.std(r2_effs, ddof=1):.4f}")
    print(f"åå½’ä¸€åŒ–+å»é‡å  RMSE: {np.mean(rmse_unnorms):.4f} Â± {np.std(rmse_unnorms, ddof=1):.4f}")
    print(f"åå½’ä¸€åŒ–+å»é‡å  MAE:  {np.mean(mae_unnorms):.4f} Â± {np.std(mae_unnorms, ddof=1):.4f}")
    print("=" * 60)
